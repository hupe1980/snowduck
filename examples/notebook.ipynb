{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snowflake.connector\n",
    "\n",
    "from snowduck import start_patch_snowflake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Persistence: In-Memory vs File-Based Storage\n",
    "\n",
    "SnowDuck supports two storage modes:\n",
    "\n",
    "**1. In-Memory (Default)**: Fast, isolated, data lost on exit\n",
    "```python\n",
    "start_patch_snowflake()  # or start_patch_snowflake(db_file=':memory:')\n",
    "```\n",
    "\n",
    "**2. File-Based**: Persistent, data survives restarts, perfect for testing\n",
    "```python\n",
    "start_patch_snowflake(db_file='my_test_data.duckdb')\n",
    "```\n",
    "\n",
    "**3. Fresh Start**: Reset clears existing data (great for notebooks!)\n",
    "```python\n",
    "start_patch_snowflake(db_file='demo.duckdb', reset=True)\n",
    "```\n",
    "\n",
    "This notebook uses **file-based storage with reset=True** for a clean start every time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable persistence with file-based storage\n",
    "# Use ':memory:' for in-memory (default) or a file path for persistence\n",
    "# reset=True gives you a fresh start (useful for notebooks!)\n",
    "start_patch_snowflake(db_file=\"snowduck_examples.duckdb\", reset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â„ï¸ðŸ¦† SnowDuck Examples\n",
    "\n",
    "This notebook demonstrates SnowDuck's features - a Snowflake-compatible SQL engine powered by DuckDB.\n",
    "\n",
    "**ðŸ’¡ Important**: Run cells from top to bottom in order! Some cells depend on previous cells.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Basic Queries](#1-basic-queries)\n",
    "2. [Database & Schema Management](#2-database--schema-management)\n",
    "3. [Table Operations & Data Seeding](#3-table-operations--data-seeding)\n",
    "4. [Conditional Logic & Expressions](#4-conditional-logic--expressions)\n",
    "5. [Advanced Queries (CTEs & Joins)](#5-advanced-queries-ctes--joins)\n",
    "6. [Information Schema](#6-information-schema)\n",
    "7. [Variables & Session Management](#7-variables--session-management)\n",
    "8. [Window Functions & Analytics](#8-window-functions--analytics)\n",
    "9. [Aggregate Functions](#9-aggregate-functions)\n",
    "10. [String Functions](#10-string-functions)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Basic Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: Hello, SnowDuck!\n"
     ]
    }
   ],
   "source": [
    "# Simple SELECT query\n",
    "with snowflake.connector.connect() as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT 'Hello, SnowDuck!' as message\")\n",
    "    result = cursor.fetchone()\n",
    "    print(f\"Message: {result[0]}\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition: 2, Multiplication: 50, Concatenation: SnowDuck\n"
     ]
    }
   ],
   "source": [
    "# Multiple columns and calculations\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            1 + 1 as addition,\n",
    "            10 * 5 as multiplication,\n",
    "            'Snow' || 'Duck' as concatenation\n",
    "    \"\"\")\n",
    "    result = cursor.fetchone()\n",
    "    print(\n",
    "        f\"Addition: {result[0]}, Multiplication: {result[1]}, Concatenation: {result[2]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Database & Schema Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Databases: ['analytics_db', 'my_database', 'snowduck_examples', 'system', 'temp']\n"
     ]
    }
   ],
   "source": [
    "# Create databases and schemas\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    # Create databases\n",
    "    cursor.execute(\"CREATE DATABASE IF NOT EXISTS my_database\")\n",
    "    cursor.execute(\"CREATE DATABASE IF NOT EXISTS analytics_db\")\n",
    "\n",
    "    # Show all databases\n",
    "    cursor.execute(\"SHOW DATABASES\")\n",
    "    databases = cursor.fetchall()\n",
    "    print(\"Databases:\", [db[1] for db in databases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schemas: []\n"
     ]
    }
   ],
   "source": [
    "# Use database and create schemas\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"USE DATABASE my_database\")\n",
    "    cursor.execute(\"CREATE SCHEMA IF NOT EXISTS public\")\n",
    "    cursor.execute(\"CREATE SCHEMA IF NOT EXISTS staging\")\n",
    "\n",
    "    cursor.execute(\"SHOW SCHEMAS\")\n",
    "    schemas = cursor.fetchall()\n",
    "    print(\"Schemas:\", [s[1] for s in schemas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Table Operations & Data Seeding\n",
    "\n",
    "**SnowDuck provides first-class data seeding with `seed_table()`:**\n",
    "\n",
    "```python\n",
    "from snowduck import seed_table\n",
    "\n",
    "# Dict of lists (easiest!)\n",
    "seed_table(conn, 'users', {\n",
    "    'id': [1, 2, 3],\n",
    "    'name': ['Alice', 'Bob', 'Carol']\n",
    "})\n",
    "\n",
    "# Or pandas DataFrame\n",
    "seed_table(conn, 'products', df)\n",
    "```\n",
    "\n",
    "Perfect for test fixtures, demos, and development!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Seeded 6 employees using seed_table()\n",
      "\n",
      "First 3 employees:\n",
      "  Alice Johnson - Engineering - $95,000\n",
      "  Bob Smith - Sales - $75,000\n",
      "  Carol White - Engineering - $105,000\n"
     ]
    }
   ],
   "source": [
    "# â­ Best Practice: Use seed_table() for easy test data!\n",
    "import pandas as pd\n",
    "\n",
    "from snowduck import seed_table\n",
    "\n",
    "# Create test data - your choice of format!\n",
    "employees_data = {\n",
    "    \"id\": [1, 2, 3, 4, 5, 6],\n",
    "    \"name\": [\n",
    "        \"Alice Johnson\",\n",
    "        \"Bob Smith\",\n",
    "        \"Carol White\",\n",
    "        \"David Brown\",\n",
    "        \"Eve Davis\",\n",
    "        \"Frank Wilson\",\n",
    "    ],\n",
    "    \"department\": [\n",
    "        \"Engineering\",\n",
    "        \"Sales\",\n",
    "        \"Engineering\",\n",
    "        \"Marketing\",\n",
    "        \"Engineering\",\n",
    "        \"Sales\",\n",
    "    ],\n",
    "    \"salary\": [95000, 75000, 105000, 68000, 98000, 82000],\n",
    "    \"hire_date\": pd.to_datetime(\n",
    "        [\n",
    "            \"2020-01-15\",\n",
    "            \"2019-03-22\",\n",
    "            \"2018-07-10\",\n",
    "            \"2021-09-01\",\n",
    "            \"2020-11-20\",\n",
    "            \"2019-05-14\",\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "with snowflake.connector.connect() as conn:\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"USE DATABASE my_database\")\n",
    "    cursor.execute(\"USE SCHEMA public\")\n",
    "\n",
    "    # One line to seed the table! ðŸŽ‰\n",
    "    rows = seed_table(conn, \"employees\", employees_data)\n",
    "    print(f\"âœ… Seeded {rows} employees using seed_table()\")\n",
    "\n",
    "    # Show first 3 employees\n",
    "    cursor.execute(\"SELECT * FROM employees LIMIT 3\")\n",
    "    results = cursor.fetchall()\n",
    "    print(\"\\nFirst 3 employees:\")\n",
    "    for row in results:\n",
    "        print(f\"  {row[1]} - {row[2]} - ${row[3]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 6 employees from Parquet file\n"
     ]
    }
   ],
   "source": [
    "# Alternative: Load from files (DuckDB's superpower!)\n",
    "# DuckDB can read CSV, Parquet, JSON directly\n",
    "import pandas as pd\n",
    "\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    # Example: Read from Parquet (if you have test data files)\n",
    "    # cursor.execute(\"CREATE TABLE sales AS SELECT * FROM 'test_data/sales.parquet'\")\n",
    "\n",
    "    # Example: Read from CSV\n",
    "    # cursor.execute(\"CREATE TABLE customers AS SELECT * FROM 'test_data/customers.csv'\")\n",
    "\n",
    "    # For this demo, we'll create a temp parquet file from our data\n",
    "    df = pd.DataFrame(employees_data)\n",
    "    df.to_parquet(\"/tmp/employees.parquet\", index=False)\n",
    "\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE OR REPLACE TABLE employees_from_file AS \n",
    "        SELECT * FROM '/tmp/employees.parquet'\n",
    "    \"\"\")\n",
    "\n",
    "    cursor.execute(\"SELECT COUNT(*) FROM employees_from_file\")\n",
    "    count = cursor.fetchone()\n",
    "    print(f\"âœ… Loaded {count[0]} employees from Parquet file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Departments:\n",
      "  Engineering: 3 employees, avg $99,333\n",
      "  Sales: 2 employees, avg $78,500\n",
      "  Marketing: 1 employees, avg $68,000\n"
     ]
    }
   ],
   "source": [
    "# Alternative Method 2: CREATE TABLE AS with inline data\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE OR REPLACE TABLE departments AS\n",
    "        SELECT * FROM (VALUES\n",
    "            ('Engineering', 3, 99333),\n",
    "            ('Sales', 2, 78500),\n",
    "            ('Marketing', 1, 68000)\n",
    "        ) AS t(name, employee_count, avg_salary)\n",
    "    \"\"\")\n",
    "\n",
    "    cursor.execute(\"SELECT * FROM departments\")\n",
    "    results = cursor.fetchall()\n",
    "    print(\"Departments:\")\n",
    "    for row in results:\n",
    "        print(f\"  {row[0]}: {row[1]} employees, avg ${row[2]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conditional Logic & Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Classification:\n",
      "----------------------------------------------------------------------\n",
      "Name            Department       Salary Level      Tenure  \n",
      "----------------------------------------------------------------------\n",
      "Carol White     Engineering  $  105,000 Senior     Veteran \n",
      "Eve Davis       Engineering  $   98,000 Mid-Level  Recent  \n",
      "Alice Johnson   Engineering  $   95,000 Mid-Level  Recent  \n",
      "Frank Wilson    Sales        $   82,000 Mid-Level  Veteran \n",
      "Bob Smith       Sales        $   75,000 Junior     Veteran \n",
      "David Brown     Marketing    $   68,000 Junior     Recent  \n"
     ]
    }
   ],
   "source": [
    "# Subquery with CASE statements\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            name,\n",
    "            department,\n",
    "            salary,\n",
    "            CASE \n",
    "                WHEN salary >= 100000 THEN 'Senior'\n",
    "                WHEN salary >= 80000 THEN 'Mid-Level'\n",
    "                ELSE 'Junior'\n",
    "            END as level,\n",
    "            CASE \n",
    "                WHEN hire_date < '2020-01-01' THEN 'Veteran'\n",
    "                ELSE 'Recent'\n",
    "            END as tenure\n",
    "        FROM employees\n",
    "        ORDER BY salary DESC\n",
    "    \"\"\")\n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    print(\"Employee Classification:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(f\"{'Name':<15} {'Department':<12} {'Salary':>10} {'Level':<10} {'Tenure':<8}\")\n",
    "    print(\"-\" * 70)\n",
    "    for row in results:\n",
    "        print(f\"{row[0]:<15} {row[1]:<12} ${row[2]:>9,} {row[3]:<10} {row[4]:<8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Advanced Queries (CTEs & Joins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Above-Average Performers:\n",
      "-------------------------------------------------------------------------------------\n",
      "Name            Department       Salary   Dept Avg  % Above\n",
      "-------------------------------------------------------------------------------------\n",
      "Carol White     Engineering  $  105,000 $   99,333     5.7%\n",
      "Frank Wilson    Sales        $   82,000 $   78,500     4.5%\n"
     ]
    }
   ],
   "source": [
    "# CTE (Common Table Expression) with multiple aggregations\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "        WITH dept_stats AS (\n",
    "            SELECT \n",
    "                department,\n",
    "                COUNT(*) as emp_count,\n",
    "                AVG(salary) as avg_salary\n",
    "            FROM employees\n",
    "            GROUP BY department\n",
    "        ),\n",
    "        high_performers AS (\n",
    "            SELECT \n",
    "                e.name,\n",
    "                e.department,\n",
    "                e.salary,\n",
    "                ds.avg_salary\n",
    "            FROM employees e\n",
    "            JOIN dept_stats ds ON e.department = ds.department\n",
    "            WHERE e.salary > ds.avg_salary\n",
    "        )\n",
    "        SELECT \n",
    "            name,\n",
    "            department,\n",
    "            salary,\n",
    "            ROUND(avg_salary, 0) as dept_avg,\n",
    "            ROUND((salary - avg_salary) / avg_salary * 100, 1) as pct_above_avg\n",
    "        FROM high_performers\n",
    "        ORDER BY pct_above_avg DESC\n",
    "    \"\"\")\n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    print(\"Above-Average Performers:\")\n",
    "    print(\"-\" * 85)\n",
    "    print(\n",
    "        f\"{'Name':<15} {'Department':<12} {'Salary':>10} {'Dept Avg':>10} {'% Above':>8}\"\n",
    "    )\n",
    "    print(\"-\" * 85)\n",
    "    for row in results:\n",
    "        print(\n",
    "            f\"{row[0]:<15} {row[1]:<12} ${row[2]:>9,} ${row[3]:>9,.0f} {row[4]:>7.1f}%\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Information Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees table structure:\n",
      "--------------------------------------------------\n",
      "Column          Type            Nullable  \n",
      "--------------------------------------------------\n",
      "id              INTEGER         YES       \n",
      "name            VARCHAR         YES       \n",
      "department      VARCHAR         YES       \n",
      "salary          INTEGER         YES       \n",
      "hire_date       TIMESTAMP       YES       \n"
     ]
    }
   ],
   "source": [
    "# Get column information\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT column_name, data_type, is_nullable\n",
    "        FROM information_schema.columns\n",
    "        WHERE table_name = 'employees'\n",
    "        ORDER BY ordinal_position\n",
    "    \"\"\")\n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    print(\"Employees table structure:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Column':<15} {'Type':<15} {'Nullable':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    for row in results:\n",
    "        print(f\"{row[0]:<15} {row[1]:<15} {row[2]:<10}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in my_database (8 total):\n",
      "  _snowduck_account._information_schema._columns (VIEW)\n",
      "  _snowduck_account._information_schema._columns_ext (BASE TABLE)\n",
      "  _snowduck_account._information_schema._tables_ext (BASE TABLE)\n",
      "  _snowduck_account._information_schema._users_ext (BASE TABLE)\n",
      "  _snowduck_account._information_schema._warehouses_ext (BASE TABLE)\n",
      "  snowduck_examples.main.departments (BASE TABLE)\n",
      "  snowduck_examples.main.employees (BASE TABLE)\n",
      "  snowduck_examples.main.employees_from_file (BASE TABLE)\n"
     ]
    }
   ],
   "source": [
    "# List all tables in the database\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"USE DATABASE my_database\")\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT table_catalog, table_schema, table_name, table_type\n",
    "        FROM information_schema.tables\n",
    "        WHERE table_schema NOT IN ('information_schema', 'pg_catalog')\n",
    "        ORDER BY table_schema, table_name\n",
    "    \"\"\")\n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    print(f\"Tables in my_database ({len(results)} total):\")\n",
    "    for row in results:\n",
    "        print(f\"  {row[0]}.{row[1]}.{row[2]} ({row[3]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Variables & Session Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Set session variables: min_salary=80000, target_dept='Engineering'\n",
      "\n",
      "High-earning Engineers:\n",
      "  Carol White: $105,000\n",
      "  Eve Davis: $98,000\n",
      "  Alice Johnson: $95,000\n"
     ]
    }
   ],
   "source": [
    "# Session variables - Set them first!\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    # Set variables\n",
    "    cursor.execute(\"SET min_salary = 80000\")\n",
    "    cursor.execute(\"SET target_dept = 'Engineering'\")\n",
    "    print(\"âœ… Set session variables: min_salary=80000, target_dept='Engineering'\")\n",
    "\n",
    "    # Use variables in queries\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT name, salary, department\n",
    "        FROM employees\n",
    "        WHERE salary >= $min_salary\n",
    "        AND department = $target_dept\n",
    "        ORDER BY salary DESC\n",
    "    \"\"\")\n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    print(\"\\nHigh-earning Engineers:\")\n",
    "    for row in results:\n",
    "        print(f\"  {row[0]}: ${row[1]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Variable in same connection: Hello from new connection\n"
     ]
    }
   ],
   "source": [
    "# Note: Session variables are connection-scoped, not global\n",
    "# They need to be set again for each new connection\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"SET test_var = 'Hello from new connection'\")\n",
    "    cursor.execute(\"SELECT $test_var\")\n",
    "    result = cursor.fetchone()\n",
    "    print(f\"âœ… Variable in same connection: {result[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Window Functions & Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Rankings:\n",
      "--------------------------------------------------------------------------------\n",
      "Name            Department       Salary  Overall   Dept  Dense\n",
      "--------------------------------------------------------------------------------\n",
      "Carol White     Engineering  $  105,000        1      1      1\n",
      "Eve Davis       Engineering  $   98,000        2      2      2\n",
      "Alice Johnson   Engineering  $   95,000        3      3      3\n",
      "Frank Wilson    Sales        $   82,000        4      1      4\n",
      "Bob Smith       Sales        $   75,000        5      2      5\n",
      "David Brown     Marketing    $   68,000        6      1      6\n"
     ]
    }
   ],
   "source": [
    "# Window functions for ranking and analytics\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            name,\n",
    "            department,\n",
    "            salary,\n",
    "            ROW_NUMBER() OVER (ORDER BY salary DESC) as overall_rank,\n",
    "            RANK() OVER (PARTITION BY department ORDER BY salary DESC) as dept_rank,\n",
    "            DENSE_RANK() OVER (ORDER BY salary DESC) as dense_rank\n",
    "        FROM employees\n",
    "        ORDER BY salary DESC\n",
    "    \"\"\")\n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    print(\"Employee Rankings:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\n",
    "        f\"{'Name':<15} {'Department':<12} {'Salary':>10} {'Overall':>8} {'Dept':>6} {'Dense':>6}\"\n",
    "    )\n",
    "    print(\"-\" * 80)\n",
    "    for row in results:\n",
    "        print(\n",
    "            f\"{row[0]:<15} {row[1]:<12} ${row[2]:>9,} {row[3]:>8} {row[4]:>6} {row[5]:>6}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Department Statistics:\n",
      "--------------------------------------------------------------------------------\n",
      "Department: Engineering\n",
      "  Employees: 3\n",
      "  Avg Salary: $99,333.33\n",
      "  Salary Range: $95,000 - $105,000\n",
      "  Total Payroll: $298,000\n",
      "\n",
      "Department: Sales\n",
      "  Employees: 2\n",
      "  Avg Salary: $78,500.00\n",
      "  Salary Range: $75,000 - $82,000\n",
      "  Total Payroll: $157,000\n",
      "\n",
      "Department: Marketing\n",
      "  Employees: 1\n",
      "  Avg Salary: $68,000.00\n",
      "  Salary Range: $68,000 - $68,000\n",
      "  Total Payroll: $68,000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate functions with GROUP BY\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            department,\n",
    "            COUNT(*) as employee_count,\n",
    "            AVG(salary) as avg_salary,\n",
    "            MIN(salary) as min_salary,\n",
    "            MAX(salary) as max_salary,\n",
    "            SUM(salary) as total_payroll\n",
    "        FROM employees\n",
    "        GROUP BY department\n",
    "        ORDER BY avg_salary DESC\n",
    "    \"\"\")\n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    print(\"Department Statistics:\")\n",
    "    print(\"-\" * 80)\n",
    "    for row in results:\n",
    "        print(f\"Department: {row[0]}\")\n",
    "        print(f\"  Employees: {row[1]}\")\n",
    "        print(f\"  Avg Salary: ${row[2]:,.2f}\")\n",
    "        print(f\"  Salary Range: ${row[3]:,} - ${row[4]:,}\")\n",
    "        print(f\"  Total Payroll: ${row[5]:,}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. String Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Functions Demo:\n",
      "  Original: Alice Johnson\n",
      "  Upper: ALICE JOHNSON, Lower: alice johnson, Length: 13\n",
      "  Full Info: Alice Johnson - Engineering\n",
      "\n",
      "  Original: Bob Smith\n",
      "  Upper: BOB SMITH, Lower: bob smith, Length: 9\n",
      "  Full Info: Bob Smith - Sales\n",
      "\n",
      "  Original: Carol White\n",
      "  Upper: CAROL WHITE, Lower: carol white, Length: 11\n",
      "  Full Info: Carol White - Engineering\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# String manipulation functions\n",
    "with snowflake.connector.connect() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT \n",
    "            name,\n",
    "            UPPER(name) as uppercase,\n",
    "            LOWER(name) as lowercase,\n",
    "            LENGTH(name) as name_length,\n",
    "            CONCAT(name, ' - ', department) as full_info,\n",
    "            SUBSTRING(name, 1, 5) as short_name\n",
    "        FROM employees\n",
    "        WHERE id <= 3\n",
    "    \"\"\")\n",
    "\n",
    "    results = cursor.fetchall()\n",
    "    print(\"String Functions Demo:\")\n",
    "    for row in results:\n",
    "        print(f\"  Original: {row[0]}\")\n",
    "        print(f\"  Upper: {row[1]}, Lower: {row[2]}, Length: {row[3]}\")\n",
    "        print(f\"  Full Info: {row[4]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "SnowDuck provides comprehensive Snowflake SQL compatibility including:\n",
    "\n",
    "âœ… **DDL Operations**: CREATE/DROP databases, schemas, tables  \n",
    "âœ… **DML Operations**: INSERT, SELECT with complex WHERE clauses  \n",
    "âœ… **String Functions**: UPPER, LOWER, CONCAT, LENGTH, SUBSTRING  \n",
    "âœ… **Aggregate Functions**: COUNT, SUM, AVG, MIN, MAX with GROUP BY  \n",
    "âœ… **Window Functions**: ROW_NUMBER, RANK, DENSE_RANK, PARTITION BY  \n",
    "âœ… **Session Variables**: SET/SELECT $variable syntax  \n",
    "âœ… **Information Schema**: Query metadata about databases, tables, columns  \n",
    "âœ… **Advanced SQL**: CTEs, subqueries, JOINs, CASE statements  \n",
    "\n",
    "**Perfect for:**\n",
    "- ðŸ§ª Testing SQL logic locally\n",
    "- ðŸš€ Rapid prototyping  \n",
    "- ðŸ’° Development without cloud costs\n",
    "- ðŸ“Š CI/CD pipeline integration\n",
    "\n",
    "See [README.md](../README.md) for installation and more information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowduck (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
